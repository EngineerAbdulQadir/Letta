{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Self Editing Memory From Scratch Using Letta"
      ],
      "metadata": {
        "id": "Y0AIbQFgRUny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup OpenAI"
      ],
      "metadata": {
        "id": "qcg5O-JzmkAd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPmtRTtjRL-u"
      },
      "outputs": [],
      "source": [
        "from helper import get_openai_api_key\n",
        "openai_api_key = get_openai_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=openai_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "Vj1XRvMAmnEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Breaking down the LLM context window"
      ],
      "metadata": {
        "id": "y-gwffBjmttk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "YWn2XJ4amwDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a chatbot.\""
      ],
      "metadata": {
        "id": "WQKj7NlGmyOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make the completion request with the tool usage"
      ],
      "metadata": {
        "id": "N6MVFi3zm7vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt: always included in the context window\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        # chat history (evolves over time)\n",
        "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
        "    ]\n",
        ")\n",
        "chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "Do3Yo4q7m3F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding memory to the context"
      ],
      "metadata": {
        "id": "L_ZsyBKFnCXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory = {\"human\": \"Name: Abdul Qadir\"}\n",
        "system_prompt = \"You are a chatbot. \" \\\n",
        "+ \"You have a section of your context called [MEMORY] \" \\\n",
        "+ \"that contains information relevant to your conversation\""
      ],
      "metadata": {
        "id": "CV_fCoVNm_7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt + \"[MEMORY]\\n\" + \\\n",
        "         json.dumps(agent_memory)},\n",
        "        # chat history\n",
        "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
        "    ],\n",
        ")\n",
        "chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "xUfdjyF5nLnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modifing the memory with tools"
      ],
      "metadata": {
        "id": "QaBcjCqRnXHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory = {\"human\": \"\", \"agent\": \"\"}\n",
        "\n",
        "def core_memory_save(section: str, memory: str):\n",
        "    agent_memory[section] += '\\n'\n",
        "    agent_memory[section] += memory"
      ],
      "metadata": {
        "id": "KsRlNuTsnYLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory"
      ],
      "metadata": {
        "id": "naL11qQfnZsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "core_memory_save(\"human\", \"The human's name is Mussayab\")"
      ],
      "metadata": {
        "id": "JkeJJdlmndL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory"
      ],
      "metadata": {
        "id": "kdoA78Tinkde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool description"
      ],
      "metadata": {
        "id": "gPVKWs9znvFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "core_memory_save_description = \"Save important information about you,\" \\\n",
        "+ \"the agent or the human you are chatting with.\"\n",
        "\n",
        "# arguments into the tool (generated by the LLM)\n",
        "# defines what the agent must generate to input into the tool\n",
        "core_memory_save_properties = \\\n",
        "{\n",
        "    # arg 1: section of memory to edit\n",
        "    \"section\": {\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"human\", \"agent\"],\n",
        "        \"description\": \"Must be either 'human' \" \\\n",
        "        + \"(to save information about the human) or 'agent'\" \\\n",
        "        + \"(to save information about yourself)\",\n",
        "    },\n",
        "    # arg 2: memory to save\n",
        "    \"memory\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"Memory to save in the section\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# tool schema (passed to OpenAI)\n",
        "core_memory_save_metadata = \\\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"core_memory_save\",\n",
        "            \"description\": core_memory_save_description,\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": core_memory_save_properties,\n",
        "                \"required\": [\"section\", \"memory\"],\n",
        "            },\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "_XnZdNyEnl1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory = {\"human\": \"\"}\n",
        "system_prompt = \"You are a chatbot. \" \\\n",
        "+ \"You have a section of your context called [MEMORY] \" \\\n",
        "+ \"that contains information relevant to your conversation\"\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        # memory\n",
        "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
        "        # chat history\n",
        "        {\"role\": \"user\", \"content\": \"My name is Abdul Qadir\"},\n",
        "    ],\n",
        "    # tool schemas\n",
        "    tools=[core_memory_save_metadata]\n",
        ")\n",
        "response = chat_completion.choices[0]\n",
        "response"
      ],
      "metadata": {
        "id": "GFXoataynx0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Executing the tool"
      ],
      "metadata": {
        "id": "-1tJK5qkn20H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
        "arguments"
      ],
      "metadata": {
        "id": "nu8rGrcun0we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the function with the specified arguments\n",
        "core_memory_save(**arguments)"
      ],
      "metadata": {
        "id": "BjmRhESyn_EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory"
      ],
      "metadata": {
        "id": "1Y8AbK8toAf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the next agent step"
      ],
      "metadata": {
        "id": "XbOLNiMxoEfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        # memory\n",
        "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
        "        # chat history\n",
        "        {\"role\": \"user\", \"content\": \"what is my name\"},\n",
        "    ],\n",
        "    tools=[core_memory_save_metadata]\n",
        ")\n",
        "response = chat_completion.choices[0]\n",
        "response.message"
      ],
      "metadata": {
        "id": "0min7tvyoDuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing an agentic loop"
      ],
      "metadata": {
        "id": "X6pYAhKeoLr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_memory = {\"human\": \"\"}"
      ],
      "metadata": {
        "id": "VjPbd0F9oMk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_os = system_prompt \\\n",
        "+ \"\\n. You must either call a tool (core_memory_save) or\" \\\n",
        "+ \"write a response to the user. \" \\\n",
        "+ \"Do not take the same actions multiple times!\" \\\n",
        "+ \"When you learn new information, make sure to always\" \\\n",
        "+ \"call the core_memory_save tool.\""
      ],
      "metadata": {
        "id": "y_0E5o0loemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_step(user_message):\n",
        "\n",
        "    # prefix messages with system prompt and memory\n",
        "    messages = [\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt_os},\n",
        "        # memory\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # append the most recent message\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # agentic loop\n",
        "    while True:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            tools=[core_memory_save_metadata]\n",
        "        )\n",
        "        response = chat_completion.choices[0]\n",
        "\n",
        "        # update the messages with the agent's response\n",
        "        messages.append(response.message)\n",
        "\n",
        "        # if NOT calling a tool (responding to the user), return\n",
        "        if not response.message.tool_calls:\n",
        "            return response.message.content\n",
        "\n",
        "        # if calling a tool, execute the tool\n",
        "        else:\n",
        "            print(\"TOOL CALL:\", response.message.tool_calls[0].function)\n",
        "\n",
        "            # parse the arguments from the LLM function call\n",
        "            arguments = json.loads(\n",
        "                response.message.tool_calls[0].function.arguments\n",
        "            )\n",
        "\n",
        "            # run the function with the specified arguments\n",
        "            core_memory_save(**arguments)\n",
        "\n",
        "            # add the tool call response to the message history\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": response.message.tool_calls[0].id,\n",
        "                \"name\": \"core_memory_save\",\n",
        "                \"content\": f\"Updated memory: {json.dumps(agent_memory)}\"\n",
        "            })"
      ],
      "metadata": {
        "id": "XxhjwfTEoifG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_step(\"my name is Abdul Qadir.\")"
      ],
      "metadata": {
        "id": "R4JA7OFnok54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The End..."
      ],
      "metadata": {
        "id": "_oiFCrcEopGQ"
      }
    }
  ]
}