{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic RAG & External Memory Using Letta"
      ],
      "metadata": {
        "id": "iIWhnpVn1wNO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqJHAD0p1vF6"
      },
      "outputs": [],
      "source": [
        "!rm  -f ~/.letta/sqlite.db"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup a client"
      ],
      "metadata": {
        "id": "Hx9CsTHq1_6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper import nb_print, load_env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "_ = load_dotenv()"
      ],
      "metadata": {
        "id": "GRY0FwDm2DNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from letta import create_client\n",
        "\n",
        "client = create_client()"
      ],
      "metadata": {
        "id": "-JqpwYy62Fts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from letta.schemas.llm_config import LLMConfig\n",
        "\n",
        "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))"
      ],
      "metadata": {
        "id": "A0G4k7iT2HXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data into archival memory"
      ],
      "metadata": {
        "id": "5n-1snw22JLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = client.create_source(\"employee_handbook\")\n",
        "source"
      ],
      "metadata": {
        "id": "t2k8vD0e2KL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.load_file_into_source(\n",
        "    filename=\"handbook.pdf\",\n",
        "    source_id=source.id\n",
        ")"
      ],
      "metadata": {
        "id": "8vo0uk__2T05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_state = client.create_agent()"
      ],
      "metadata": {
        "id": "-KwsAkNa2U41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.attach_source_to_agent(\n",
        "    agent_id=agent_state.id,\n",
        "    source_id=source.id\n",
        ")"
      ],
      "metadata": {
        "id": "0ktguU5a2caU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.list_attached_sources(agent_state.id)"
      ],
      "metadata": {
        "id": "aarD4jCT2dDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"Search archival for our company's vacation policies\",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ],
      "metadata": {
        "id": "49zb78pJ2k7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting data via tools"
      ],
      "metadata": {
        "id": "mT0nlEcl2oJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_birthday_db(self, name: str):\n",
        "    \"\"\"\n",
        "    This tool queries an external database to\n",
        "    lookup the birthday of someone given their name.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name to look up\n",
        "\n",
        "    Returns:\n",
        "        birthday (str): The birthday in mm-dd-yyyy format\n",
        "\n",
        "    \"\"\"\n",
        "    my_fake_data = {\n",
        "        \"Abdul Qadir\": \"03-06-1997\",\n",
        "        \"Mussayab\": \"03-06-1997\"\n",
        "    }\n",
        "    name = name.lower()\n",
        "    if name not in my_fake_data:\n",
        "        return None\n",
        "    else:\n",
        "        return my_fake_data[name]"
      ],
      "metadata": {
        "id": "2Q6oIm0h2pI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "birthday_tool = client.create_tool(query_birthday_db)"
      ],
      "metadata": {
        "id": "r4c3l68A2x-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "birthday_tool"
      ],
      "metadata": {
        "id": "GveqKhsg20tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from letta.schemas.memory import ChatMemory\n",
        "\n",
        "agent_state = client.create_agent(\n",
        "    name=\"birthday_agent\",\n",
        "    tools=[birthday_tool.name],\n",
        "    memory=ChatMemory(\n",
        "        human=\"My name is Abdul Qadir\",\n",
        "        persona=\"You are a agent with access to a birthday_db \" \\\n",
        "        + \"that you use to lookup information about users' birthdays.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "7zzdHadl22aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"When is my birthday?\",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ],
      "metadata": {
        "id": "39wrwTvE25JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading tools from Langchain"
      ],
      "metadata": {
        "id": "caa0YMlq29YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"
      ],
      "metadata": {
        "id": "94q8IbI12_aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import TavilySearchResults\n",
        "from letta.schemas.tool import Tool\n",
        "\n",
        "search = TavilySearchResults()"
      ],
      "metadata": {
        "id": "5v7eKYeH3CAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.run(\"What's Obama's first name?\")"
      ],
      "metadata": {
        "id": "4bCaauQp3DYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the tool to Letta Tool"
      ],
      "metadata": {
        "id": "3Zq_hkSO3Lj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = Tool.from_langchain(TavilySearchResults())"
      ],
      "metadata": {
        "id": "FViJIbNd3IIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persist the tool"
      ],
      "metadata": {
        "id": "SJNGr3fg3PV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.add_tool(search_tool)"
      ],
      "metadata": {
        "id": "1LUi7KUJ3TeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "research_agent_persona = f\"\"\"\n",
        "You have access to a web via a {search_tool.name} tool.\n",
        "Use this tool to respond to users' questions, by summarizing the\n",
        "{search_tool.name}\n",
        "and also providing the `url` that the information was from as a\n",
        "reference.\n",
        "\n",
        "<Example>\n",
        "User: 'What is Obama's first name?'\n",
        "Assistant: 'Obama's first name is Barack.\n",
        "\n",
        "Sources:\n",
        "[1] https://www.britannica.com/biography/Barack-Obama\n",
        "[2] https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'\n",
        "</Example>\n",
        "Your MUST provide URLs that you used to generate the answer, or you will be terminated.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xlQdLTNO3VBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_state = client.create_agent(\n",
        "    name=\"research_agent\",\n",
        "    tools=[search_tool.name],\n",
        "    memory=ChatMemory(\n",
        "        human=\"My name is Abdul Qadir\",\n",
        "        persona=research_agent_persona\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "-svvb3wT3YKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"Who founded OpenAI? \",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ],
      "metadata": {
        "id": "v1jox3lA3b_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from letta.schemas.llm_config import LLMConfig\n",
        "\n",
        "agent_state = client.create_agent(\n",
        "    name=\"gpt4_search_agent\",\n",
        "    tools=[search_tool.name],\n",
        "    memory=ChatMemory(\n",
        "        human=\"My name is Sarah\",\n",
        "        persona=research_agent_persona\n",
        "    ),\n",
        "    #llm_config=LLMConfig.default_config('gpt-4')\n",
        "    llm_config=LLMConfig.default_config('gpt-4o-mini')\n",
        ")"
      ],
      "metadata": {
        "id": "S16lrGlp3dph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"Who founded OpenAI? \",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ],
      "metadata": {
        "id": "aAlazRJ43jSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The End..."
      ],
      "metadata": {
        "id": "YypIRU5R3l91"
      }
    }
  ]
}